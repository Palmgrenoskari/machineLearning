{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model VGG16\n",
    "\n",
    "## Work in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define some parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 100\n",
    "img_width = 100\n",
    "batch_size = 32\n",
    "num_classes = 21\n",
    "epochs = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8177 images belonging to 21 classes.\n",
      "Found 2038 images belonging to 21 classes.\n",
      "Found 3428 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/Palmg/Desktop/fruits-360/Training',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/Palmg/Desktop/fruits-360/Training',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C:/Users/Palmg/Desktop/fruits-360/Test',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model - Only run 1/3 of the Model codeblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 25\u001b[0m\n\u001b[0;32m     15\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     baseline\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m history \u001b[39m=\u001b[39m model_vgg16\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     26\u001b[0m     train_generator,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     29\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping]\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[39m# Evaluation\u001b[39;00m\n\u001b[0;32m     34\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3690\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   3685\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3686\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3687\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[0;32m   3688\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3689\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3690\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3691\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3692\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3693\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3694\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Base\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Model\n",
    "model_vgg16 = Sequential()\n",
    "model_vgg16.add(vgg16)\n",
    "model_vgg16.add(Flatten())\n",
    "model_vgg16.add(Dense(256, activation='relu'))\n",
    "model_vgg16.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_delta=0.01,\n",
    "    baseline=0.99\n",
    ")\n",
    "\n",
    "# Training\n",
    "history = model_vgg16.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(test_generator,verbose=1)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 Model - Only run 1/3 of the Model codeblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 75s 278ms/step - loss: 0.5241 - accuracy: 0.9248 - val_loss: 0.3225 - val_accuracy: 0.9244\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.0916 - accuracy: 0.9843 - val_loss: 1.4091 - val_accuracy: 0.8930\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 0.1287 - accuracy: 0.9831 - val_loss: 2.1492 - val_accuracy: 0.8135\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1296 - accuracy: 0.9776 - val_loss: 0.0918 - val_accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 72s 283ms/step - loss: 0.0371 - accuracy: 0.9936 - val_loss: 3.6163e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 70s 273ms/step - loss: 0.0676 - accuracy: 0.9889 - val_loss: 0.1332 - val_accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 78s 306ms/step - loss: 0.0828 - accuracy: 0.9875 - val_loss: 0.3400 - val_accuracy: 0.9082\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 75s 293ms/step - loss: 0.0736 - accuracy: 0.9886 - val_loss: 1.2769e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 74s 291ms/step - loss: 0.0225 - accuracy: 0.9965 - val_loss: 0.0648 - val_accuracy: 0.9755\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 74s 290ms/step - loss: 0.0903 - accuracy: 0.9874 - val_loss: 0.2761 - val_accuracy: 0.9347\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.5827 - accuracy: 0.8915\n",
      "Test accuracy: 0.8914819359779358\n"
     ]
    }
   ],
   "source": [
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "model_resnet50 = Sequential()\n",
    "model_resnet50.add(resnet50)\n",
    "model_resnet50.add(Flatten())\n",
    "model_resnet50.add(Dense(256, activation='relu'))\n",
    "model_resnet50.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_resnet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_delta=0.01,\n",
    "    baseline=0.99\n",
    ")\n",
    "\n",
    "history = model_resnet50.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator,verbose=1)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e3d2864960cda1cc89e7405ec595e77e7ac30692c1b4230c1dcf8d9a5036813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
